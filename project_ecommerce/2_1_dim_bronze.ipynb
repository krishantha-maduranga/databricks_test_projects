{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e8345e2-1fe5-4200-b504-7041ef999a2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, TimestampType, FloatType\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "926807ef-6362-4019-8b2b-495f5c25027b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_name = 'my_databricks_workspace'\n",
    "\n",
    "# Define Schema for the data file\n",
    "brand_schema = StructType([\n",
    "    StructField(\"brand_code\", StringType(), False),\n",
    "    StructField(\"brand_name\", StringType(), True),\n",
    "    StructField(\"category_code\", StringType(), True)   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d0fde58-031d-4f3b-8a1f-1a172d7e2ba9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_data_path = \"/Volumes/my_databricks_workspace/source_data/raw/brands/*.csv\"\n",
    "\n",
    "df = spark.read.option('header', \"true\").option(\"delimiter\", \",\").schema(brand_schema).csv(raw_data_path)\n",
    "\n",
    "# add metadata columns\n",
    "df = df.withColumn(\"_source_file\", F.col(\"_metadata.file_path\")).withColumn(\"ingested_at\",F.current_timestamp())\n",
    "\n",
    "display(df.limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a46fb297-756f-47bf-991f-8f9bd50bd692",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bronze - Ingesting Brand Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4034269c-3b66-466b-a482-d106b9b28be9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a Delta table in Bronze layer using the above DF\n",
    "df.write.format(\"delta\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .saveAsTable(f\"{catalog_name}.ecommerce_bronze.brz_brands\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9defe322-0191-412f-b78c-bbc5e7fe8bcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bronze - Ingesting Category Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0609818e-02df-4b20-ad89-62fe6850e2c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "category_schema = StructType([\n",
    "    StructField(\"category_code\", StringType(), False),\n",
    "    StructField(\"category_name\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Load data using the schema defined\n",
    "raw_data_path = \"/Volumes/my_databricks_workspace/source_data/raw/category/*.csv\"\n",
    "\n",
    "df_raw = spark.read.option(\"header\", \"true\").option(\"delimiter\", \",\").schema(category_schema).csv(raw_data_path)\n",
    "\n",
    "# Add metadata columns\n",
    "df_raw = df_raw.withColumn(\"_ingested_at\", F.current_timestamp()) \\\n",
    "               .withColumn(\"_source_file\", F.col(\"_metadata.file_path\"))\n",
    "\n",
    "\n",
    "# Write raw data to the Bronze layer (catalog: my_databricks_workspace, schema: ecommerce_bronze, table: brz_category)\n",
    "df_raw.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{catalog_name}.ecommerce_bronze.brz_category\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ec2d2a9-4682-43f8-92fe-a681200edf8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bronze - Ingesting Product Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f49e271-a0ed-459a-9dde-9c93966024f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "products_schema = StructType([\n",
    "    StructField(\"product_id\", StringType(), False),\n",
    "    StructField(\"sku\", StringType(), True),\n",
    "    StructField(\"category_code\", StringType(), True),\n",
    "    StructField(\"brand_code\", StringType(), True),\n",
    "    StructField(\"color\", StringType(), True),\n",
    "    StructField(\"size\", StringType(), True),\n",
    "    StructField(\"material\", StringType(), True),\n",
    "    StructField(\"weight_grams\", StringType(), True),  #datatype is string due to incoming data contain anamolies\n",
    "    StructField(\"length_cm\", StringType(), True),     #datatype is string due to incoming data contain anamolies\n",
    "    StructField(\"width_cm\", FloatType(), True),\n",
    "    StructField(\"height_cm\", FloatType(), True),\n",
    "    StructField(\"rating_count\", IntegerType(), True),\n",
    "    StructField(\"file_name\", StringType(), False),\n",
    "    StructField(\"ingest_timestamp\", TimestampType(), False)\n",
    "])\n",
    "\n",
    "# Load data using the schema defined\n",
    "raw_data_path = \"/Volumes/my_databricks_workspace/source_data/raw/products/*.csv\"\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").option(\"delimiter\", \",\").schema(products_schema).csv(raw_data_path) \\\n",
    "    .withColumn(\"file_name\", F.col(\"_metadata.file_path\")) \\\n",
    "    .withColumn(\"ingest_timestamp\", F.current_timestamp())\n",
    "\n",
    "# Write raw data to the Bronze layer (catalog: my_databricks_workspace, schema: ecommerce_bronze, table: brz_products)\n",
    "df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{catalog_name}.ecommerce_bronze.brz_products\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83bd4f2c-3701-475e-a144-1495466a56c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bronze - Ingesting Customer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee4e82ae-f583-4e6a-b2ee-4bcf7eadd504",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customers_schema = StructType([\n",
    "    StructField(\"customer_id\", StringType(), False),\n",
    "    StructField(\"phone\", StringType(), True),\n",
    "    StructField(\"country_code\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Load data using the schema defined\n",
    "raw_data_path =\"/Volumes/my_databricks_workspace/source_data/raw/customers/*.csv\"\n",
    "\n",
    "df_raw = spark.read.option(\"header\", \"true\").option(\"delimiter\", \",\").schema(customers_schema).csv(raw_data_path) \\\n",
    "    .withColumn(\"file_name\", F.col(\"_metadata.file_path\")) \\\n",
    "    .withColumn(\"ingest_timestamp\", F.current_timestamp())\n",
    "\n",
    "# Write raw data to the Bronze layer (catalog: my_databricks_workspace, schema: ecommerce_bronze, table: brz_customers)\n",
    "df_raw.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{catalog_name}.ecommerce_bronze.brz_customers\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2a0ac2f-53d2-48b7-b052-0ac93501b01b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bronze - Ingesting Data related to Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99aba97b-604f-4686-9bc1-e458b24a21f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define schema for the data file\n",
    "date_schema = StructType([\n",
    "    StructField(\"date\", StringType(), True),           # Raw date in string format\n",
    "    StructField(\"year\", IntegerType(), True),          # Year\n",
    "    StructField(\"day_name\", StringType(), True),       # Day name (can be mixed case)\n",
    "    StructField(\"quarter\", IntegerType(), True),       # Quarter\n",
    "    StructField(\"week_of_year\", IntegerType(), True),  # Week of year (can be negative)\n",
    "])\n",
    "\n",
    "# Load data using the schema defined\n",
    "raw_data_path = f\"/Volumes/my_databricks_workspace/source_data/raw/date/*.csv\" \n",
    "\n",
    "df_raw = spark.read.option(\"header\", \"true\").option(\"delimiter\", \",\").schema(date_schema).csv(raw_data_path)\n",
    "\n",
    "# Add metadata columns\n",
    "df_raw = df_raw.withColumn(\"_ingested_at\", F.current_timestamp()) \\\n",
    "               .withColumn(\"_source_file\", F.col(\"_metadata.file_path\"))\n",
    "\n",
    "\n",
    "# Write raw data to the Bronze layer (catalog: my_databricks_workspace, schema: ecommerce_bronze, table: brz_calendar) \n",
    "df_raw.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{catalog_name}.ecommerce_bronze.brz_calendar\")     "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4917273136825145,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "2_1_dim_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
